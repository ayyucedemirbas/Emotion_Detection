{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1w8HyZRfIqUxMzRqJEzL9kWtZqQ2lD1Qm",
      "authorship_tag": "ABX9TyP1d9sE2coAAAXUYZ6pxvF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayyucedemirbas/Emotion_Detection/blob/main/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a6EFcb9_MPL"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/fer2013-20211101T153413Z-001.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
        "import os"
      ],
      "metadata": {
        "id": "nQweDnEp_kvA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "Hj5svIX2CGfP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL"
      ],
      "metadata": {
        "id": "vpAeKQ7zCJkJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image "
      ],
      "metadata": {
        "id": "u92AhbpcCRtP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=6\n",
        "img_rows,img_cols=48,48\n",
        "batch_size=64"
      ],
      "metadata": {
        "id": "TRKw0i3Q_w7X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir='fer2013/train'\n",
        "validation_data_dir='fer2013/validation'"
      ],
      "metadata": {
        "id": "TTyhkHpw_0B-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    width_shift_range=0.4,\n",
        "    height_shift_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "t9CI-c3e_2xT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "                        train_data_dir,\n",
        "                        color_mode='grayscale',\n",
        "                        target_size=(img_rows,img_cols),\n",
        "                        batch_size=batch_size,\n",
        "                        class_mode='categorical',\n",
        "                        shuffle=True)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "                                validation_data_dir,\n",
        "                                color_mode='grayscale',\n",
        "                                target_size=(img_rows,img_cols),\n",
        "                                batch_size=batch_size,\n",
        "                                class_mode='categorical',\n",
        "                                shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxPOBUn-_5b7",
        "outputId": "d13f6b38-28b3-4f73-a9e3-687d1321f695"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28353 images belonging to 6 classes.\n",
            "Found 3534 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "              Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',\n",
        "              input_shape=(img_rows,img_cols,1)),\n",
        "              Activation('elu'),\n",
        "              BatchNormalization(),\n",
        "              Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',\n",
        "                     input_shape=(img_rows,img_cols,1)),\n",
        "              Activation('elu'),\n",
        "              BatchNormalization(),\n",
        "              MaxPooling2D(pool_size=(2,2)),\n",
        "              Dropout(0.2),\n",
        "\n",
        "\n",
        "\n",
        "            Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "            Activation('elu'),\n",
        "            BatchNormalization(),\n",
        "            Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "            Activation('elu'),\n",
        "            BatchNormalization(),\n",
        "            MaxPooling2D(pool_size=(2,2)),\n",
        "            Dropout(0.2),\n",
        "\n",
        "\n",
        "          Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "          Activation('elu'),\n",
        "          BatchNormalization(),\n",
        "          Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "          Activation('elu'),\n",
        "          BatchNormalization(),\n",
        "          MaxPooling2D(pool_size=(2,2)),\n",
        "          Dropout(0.2),\n",
        "\n",
        "\n",
        "\n",
        "        Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "        Activation('elu'),\n",
        "        BatchNormalization(),\n",
        "        Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "        Activation('elu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Dropout(0.2),\n",
        "\n",
        "\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64,kernel_initializer='he_normal'),\n",
        "        Activation('elu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "\n",
        "\n",
        "        Dense(64,kernel_initializer='he_normal'),\n",
        "        Activation('elu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "\n",
        "\n",
        "        Dense(num_classes,kernel_initializer='he_normal'),\n",
        "        Activation('softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "BMDK_8Iz_6kN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('EmotionDetectionModel.h5',\n",
        "                             monitor='val_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True\n",
        "                          )\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=3,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)\n",
        "\n",
        "callbacks = [checkpoint,reduce_lr]"
      ],
      "metadata": {
        "id": "rJrnHYf6CMAp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_train_samples = 24176\n",
        "nb_validation_samples = 3006\n",
        "epochs=50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjjtEg7lCWr8",
        "outputId": "0dba3754-c973-413a-c096-6fbd67f7ee95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit_generator(\n",
        "                train_generator,\n",
        "                steps_per_epoch=nb_train_samples//batch_size,\n",
        "                epochs=epochs,\n",
        "                callbacks=callbacks,\n",
        "                validation_data=validation_generator,\n",
        "                validation_steps=nb_validation_samples//batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmVYjS4VCZBe",
        "outputId": "2d333b95-f570-43bd-cf3a-a9e1fe9729ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 2.1569 - accuracy: 0.1958\n",
            "Epoch 00001: val_loss improved from inf to 1.76665, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 37s 88ms/step - loss: 2.1569 - accuracy: 0.1958 - val_loss: 1.7667 - val_accuracy: 0.2374 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.8161 - accuracy: 0.2221\n",
            "Epoch 00002: val_loss improved from 1.76665 to 1.74663, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.8161 - accuracy: 0.2221 - val_loss: 1.7466 - val_accuracy: 0.2551 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.7537 - accuracy: 0.2464\n",
            "Epoch 00003: val_loss improved from 1.74663 to 1.73160, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.7537 - accuracy: 0.2464 - val_loss: 1.7316 - val_accuracy: 0.2588 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.7323 - accuracy: 0.2625\n",
            "Epoch 00004: val_loss improved from 1.73160 to 1.72934, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.7323 - accuracy: 0.2625 - val_loss: 1.7293 - val_accuracy: 0.2629 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.7158 - accuracy: 0.2703\n",
            "Epoch 00005: val_loss did not improve from 1.72934\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.7158 - accuracy: 0.2703 - val_loss: 1.7960 - val_accuracy: 0.2605 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.6813 - accuracy: 0.2886\n",
            "Epoch 00006: val_loss improved from 1.72934 to 1.59478, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.6813 - accuracy: 0.2886 - val_loss: 1.5948 - val_accuracy: 0.3553 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.6141 - accuracy: 0.3289\n",
            "Epoch 00007: val_loss improved from 1.59478 to 1.58880, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.6141 - accuracy: 0.3289 - val_loss: 1.5888 - val_accuracy: 0.3910 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.5505 - accuracy: 0.3670\n",
            "Epoch 00008: val_loss improved from 1.58880 to 1.56953, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.5505 - accuracy: 0.3670 - val_loss: 1.5695 - val_accuracy: 0.4270 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.5004 - accuracy: 0.3973\n",
            "Epoch 00009: val_loss did not improve from 1.56953\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.5004 - accuracy: 0.3973 - val_loss: 1.6176 - val_accuracy: 0.4127 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.4502 - accuracy: 0.4230\n",
            "Epoch 00010: val_loss improved from 1.56953 to 1.49322, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.4502 - accuracy: 0.4230 - val_loss: 1.4932 - val_accuracy: 0.4372 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.4134 - accuracy: 0.4411\n",
            "Epoch 00011: val_loss did not improve from 1.49322\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.4134 - accuracy: 0.4411 - val_loss: 1.5484 - val_accuracy: 0.4249 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.3970 - accuracy: 0.4489\n",
            "Epoch 00012: val_loss improved from 1.49322 to 1.49280, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.3970 - accuracy: 0.4489 - val_loss: 1.4928 - val_accuracy: 0.4626 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.3678 - accuracy: 0.4605\n",
            "Epoch 00013: val_loss did not improve from 1.49280\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.3678 - accuracy: 0.4605 - val_loss: 1.5205 - val_accuracy: 0.4823 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.3471 - accuracy: 0.4712\n",
            "Epoch 00014: val_loss improved from 1.49280 to 1.43502, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.3471 - accuracy: 0.4712 - val_loss: 1.4350 - val_accuracy: 0.4851 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.3370 - accuracy: 0.4785\n",
            "Epoch 00015: val_loss did not improve from 1.43502\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.3370 - accuracy: 0.4785 - val_loss: 1.4409 - val_accuracy: 0.4905 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.3174 - accuracy: 0.4889\n",
            "Epoch 00016: val_loss did not improve from 1.43502\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.3174 - accuracy: 0.4889 - val_loss: 1.4637 - val_accuracy: 0.4929 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.3022 - accuracy: 0.4906\n",
            "Epoch 00017: val_loss did not improve from 1.43502\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.3022 - accuracy: 0.4906 - val_loss: 1.4533 - val_accuracy: 0.5099 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2642 - accuracy: 0.5134\n",
            "Epoch 00018: val_loss improved from 1.43502 to 1.37724, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.2642 - accuracy: 0.5134 - val_loss: 1.3772 - val_accuracy: 0.5149 - lr: 2.0000e-04\n",
            "Epoch 19/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2473 - accuracy: 0.5189\n",
            "Epoch 00019: val_loss improved from 1.37724 to 1.37628, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.2473 - accuracy: 0.5189 - val_loss: 1.3763 - val_accuracy: 0.5126 - lr: 2.0000e-04\n",
            "Epoch 20/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2378 - accuracy: 0.5245\n",
            "Epoch 00020: val_loss improved from 1.37628 to 1.36315, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 85ms/step - loss: 1.2378 - accuracy: 0.5245 - val_loss: 1.3631 - val_accuracy: 0.5183 - lr: 2.0000e-04\n",
            "Epoch 21/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2370 - accuracy: 0.5261\n",
            "Epoch 00021: val_loss improved from 1.36315 to 1.36305, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.2370 - accuracy: 0.5261 - val_loss: 1.3630 - val_accuracy: 0.5312 - lr: 2.0000e-04\n",
            "Epoch 22/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2255 - accuracy: 0.5326\n",
            "Epoch 00022: val_loss did not improve from 1.36305\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.2255 - accuracy: 0.5326 - val_loss: 1.3656 - val_accuracy: 0.5268 - lr: 2.0000e-04\n",
            "Epoch 23/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2130 - accuracy: 0.5319\n",
            "Epoch 00023: val_loss improved from 1.36305 to 1.35974, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.2130 - accuracy: 0.5319 - val_loss: 1.3597 - val_accuracy: 0.5397 - lr: 2.0000e-04\n",
            "Epoch 24/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2156 - accuracy: 0.5314\n",
            "Epoch 00024: val_loss did not improve from 1.35974\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.2156 - accuracy: 0.5314 - val_loss: 1.3865 - val_accuracy: 0.5316 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2192 - accuracy: 0.5324\n",
            "Epoch 00025: val_loss improved from 1.35974 to 1.33251, saving model to EmotionDetectionModel.h5\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.2192 - accuracy: 0.5324 - val_loss: 1.3325 - val_accuracy: 0.5404 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2079 - accuracy: 0.5369\n",
            "Epoch 00026: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.2079 - accuracy: 0.5369 - val_loss: 1.3546 - val_accuracy: 0.5394 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2041 - accuracy: 0.5398\n",
            "Epoch 00027: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.2041 - accuracy: 0.5398 - val_loss: 1.3874 - val_accuracy: 0.5435 - lr: 2.0000e-04\n",
            "Epoch 28/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.2016 - accuracy: 0.5429\n",
            "Epoch 00028: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.2016 - accuracy: 0.5429 - val_loss: 1.3745 - val_accuracy: 0.5448 - lr: 2.0000e-04\n",
            "Epoch 29/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1931 - accuracy: 0.5449\n",
            "Epoch 00029: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.1931 - accuracy: 0.5449 - val_loss: 1.3623 - val_accuracy: 0.5387 - lr: 4.0000e-05\n",
            "Epoch 30/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1860 - accuracy: 0.5466\n",
            "Epoch 00030: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.1860 - accuracy: 0.5466 - val_loss: 1.3932 - val_accuracy: 0.5336 - lr: 4.0000e-05\n",
            "Epoch 31/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1880 - accuracy: 0.5446\n",
            "Epoch 00031: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1880 - accuracy: 0.5446 - val_loss: 1.3854 - val_accuracy: 0.5312 - lr: 4.0000e-05\n",
            "Epoch 32/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1829 - accuracy: 0.5489\n",
            "Epoch 00032: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.1829 - accuracy: 0.5489 - val_loss: 1.3817 - val_accuracy: 0.5346 - lr: 8.0000e-06\n",
            "Epoch 33/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1830 - accuracy: 0.5496\n",
            "Epoch 00033: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1830 - accuracy: 0.5496 - val_loss: 1.3599 - val_accuracy: 0.5411 - lr: 8.0000e-06\n",
            "Epoch 34/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1863 - accuracy: 0.5462\n",
            "Epoch 00034: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.1863 - accuracy: 0.5462 - val_loss: 1.3620 - val_accuracy: 0.5360 - lr: 8.0000e-06\n",
            "Epoch 35/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1821 - accuracy: 0.5497\n",
            "Epoch 00035: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1821 - accuracy: 0.5497 - val_loss: 1.3600 - val_accuracy: 0.5397 - lr: 1.6000e-06\n",
            "Epoch 36/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1913 - accuracy: 0.5466\n",
            "Epoch 00036: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 32s 86ms/step - loss: 1.1913 - accuracy: 0.5466 - val_loss: 1.3798 - val_accuracy: 0.5312 - lr: 1.6000e-06\n",
            "Epoch 37/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1805 - accuracy: 0.5496\n",
            "Epoch 00037: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1805 - accuracy: 0.5496 - val_loss: 1.3587 - val_accuracy: 0.5442 - lr: 1.6000e-06\n",
            "Epoch 38/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1784 - accuracy: 0.5501\n",
            "Epoch 00038: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.1784 - accuracy: 0.5501 - val_loss: 1.3844 - val_accuracy: 0.5329 - lr: 3.2000e-07\n",
            "Epoch 39/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1831 - accuracy: 0.5482\n",
            "Epoch 00039: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1831 - accuracy: 0.5482 - val_loss: 1.3890 - val_accuracy: 0.5397 - lr: 3.2000e-07\n",
            "Epoch 40/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1962 - accuracy: 0.5418\n",
            "Epoch 00040: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1962 - accuracy: 0.5418 - val_loss: 1.3743 - val_accuracy: 0.5353 - lr: 3.2000e-07\n",
            "Epoch 41/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1906 - accuracy: 0.5452\n",
            "Epoch 00041: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.1906 - accuracy: 0.5452 - val_loss: 1.3852 - val_accuracy: 0.5346 - lr: 6.4000e-08\n",
            "Epoch 42/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1842 - accuracy: 0.5442\n",
            "Epoch 00042: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1842 - accuracy: 0.5442 - val_loss: 1.3847 - val_accuracy: 0.5336 - lr: 6.4000e-08\n",
            "Epoch 43/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1797 - accuracy: 0.5508\n",
            "Epoch 00043: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1797 - accuracy: 0.5508 - val_loss: 1.3678 - val_accuracy: 0.5336 - lr: 6.4000e-08\n",
            "Epoch 44/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1861 - accuracy: 0.5467\n",
            "Epoch 00044: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 86ms/step - loss: 1.1861 - accuracy: 0.5467 - val_loss: 1.3909 - val_accuracy: 0.5377 - lr: 1.2800e-08\n",
            "Epoch 45/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1890 - accuracy: 0.5447\n",
            "Epoch 00045: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1890 - accuracy: 0.5447 - val_loss: 1.3763 - val_accuracy: 0.5370 - lr: 1.2800e-08\n",
            "Epoch 46/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1893 - accuracy: 0.5417\n",
            "Epoch 00046: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1893 - accuracy: 0.5417 - val_loss: 1.3839 - val_accuracy: 0.5367 - lr: 1.2800e-08\n",
            "Epoch 47/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.5500\n",
            "Epoch 00047: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 87ms/step - loss: 1.1788 - accuracy: 0.5500 - val_loss: 1.3703 - val_accuracy: 0.5374 - lr: 2.5600e-09\n",
            "Epoch 48/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1803 - accuracy: 0.5500\n",
            "Epoch 00048: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.1803 - accuracy: 0.5500 - val_loss: 1.3855 - val_accuracy: 0.5431 - lr: 2.5600e-09\n",
            "Epoch 49/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1789 - accuracy: 0.5509\n",
            "Epoch 00049: val_loss did not improve from 1.33251\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "377/377 [==============================] - 33s 88ms/step - loss: 1.1789 - accuracy: 0.5509 - val_loss: 1.3755 - val_accuracy: 0.5408 - lr: 2.5600e-09\n",
            "Epoch 50/50\n",
            "377/377 [==============================] - ETA: 0s - loss: 1.1800 - accuracy: 0.5472\n",
            "Epoch 00050: val_loss did not improve from 1.33251\n",
            "377/377 [==============================] - 33s 89ms/step - loss: 1.1800 - accuracy: 0.5472 - val_loss: 1.3868 - val_accuracy: 0.5306 - lr: 5.1200e-10\n"
          ]
        }
      ]
    }
  ]
}